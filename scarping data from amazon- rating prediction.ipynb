{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e61a67c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "479888fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af5efe82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating python program to search desired keywords one by one and saving links in open list prod_url\n",
    "\n",
    "# creating open list to save href links of all products \n",
    "prod_url = []\n",
    "\n",
    "# Keywords for search to which we need to scrape the data.\n",
    "keywords = ['Laptops', 'Phones', 'Headphones', 'Smart Watches', 'Cameras', 'Printers', 'Monitors','Home theater', 'Router']\n",
    "\n",
    "# website from which we will scrape data\n",
    "driver.get(\"https://www.amazon.in/\") \n",
    "\n",
    "initial_url = driver.current_url\n",
    "\n",
    "# loop for sending keywords to website and scraping href\n",
    "for i in keywords:\n",
    "    # Finding search input and giving input\n",
    "    search = driver.find_element(By.ID,\"twotabsearchtextbox\").send_keys(i)\n",
    "        \n",
    "    # clicking on search button\n",
    "    search_btn = driver.find_element(By.XPATH,\"//div[@class='nav-search-submit nav-sprite']\")\n",
    "    search_btn.click()\n",
    "    # giving time to load the webpage completely to avoid errors\n",
    "    time.sleep(5)\n",
    "    # finding href of each products mentioned in keywords\n",
    "    for j in driver.find_elements(By.XPATH,\"//h2[@class = 'a-size-mini a-spacing-none a-color-base s-line-clamp-2']/a\"):\n",
    "        prod_url.append(j.get_attribute('href'))\n",
    "    # returning to initial url    \n",
    "    driver.get(initial_url)\n",
    "# checking length of prod_url\n",
    "len(prod_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "500775b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening each 234 prod_url and scraping links of all reviews href \n",
    "# open list to save all reviews href\n",
    "rev_cli = []\n",
    "\n",
    "# loop for opening all links stored in prod_url\n",
    "for j in prod_url:\n",
    "    # opening each links of prod_url one by one\n",
    "    driver.get(j)\n",
    "    \n",
    "    try:\n",
    "        # finding links from all webpage by xpath\n",
    "        for k in driver.find_elements(By.XPATH,\"//a[@id = 'acrCustomerReviewLink']\"):\n",
    "            rev_cli.append(k.get_attribute('href'))\n",
    "    # if all reviews link is not available, it will continue to next page,so avoiding NoSuchElementException \n",
    "    except NoSuchElementException as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b0e74f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "519"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking length of open list\n",
    "len(rev_cli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da6ba73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now opening each links as stored in list above\n",
    "# creating open list for storing all reviews href\n",
    "all_reviews = []\n",
    "\n",
    "for l in rev_cli:\n",
    "    # opening each links as stored in cli_rev open list\n",
    "    driver.get(l)\n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:\n",
    "        # finding links from all webpage by xpath\n",
    "        all_rev = driver.find_element(By.XPATH,\"//div[@id = 'reviews-medley-footer']/div[2]/a\")\n",
    "        all_reviews.append(all_rev.get_attribute('href'))\n",
    "        # if all reviews link is not available, it will continue to next page,so avoiding NoSuchElementException \n",
    "    except NoSuchElementException as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e80ba0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking length of all reviews link\n",
    "len(all_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d75ac7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally opening all_reviews link and scraping ratings and reviews data from all webpages.\n",
    "# creating open list to save scraped data\n",
    "ratings = []\n",
    "reviews = []\n",
    "\n",
    "# opening each link to begin the scaping\n",
    "for m in all_reviews:\n",
    "    driver.get(m)\n",
    "    time.sleep(15)\n",
    "    \n",
    "    # loop to open link till page 5 and scraping data of reviews and ratings of products\n",
    "    for n in range(0,5):\n",
    "        for o in driver.find_elements(By.XPATH,\"//div[@class = 'a-section review aok-relative']/div/div/div[2]/a[1]\"):\n",
    "            ratings.append(o.get_attribute('title').replace(' out of 5 stars',''))\n",
    "            \n",
    "        for p in driver.find_elements(By.XPATH,\"//div[@class = 'a-section review aok-relative']/div/div/div[4]/span/span\"):\n",
    "            reviews.append(p.text)\n",
    "                        \n",
    "        try:\n",
    "            next_page = driver.find_element(By.XPATH,\"//ul[@class = 'a-pagination']/li[2]/a\")\n",
    "            driver.get(next_page.get_attribute('href'))\n",
    "        except NoSuchElementException as e:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a8c2dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>I'm writing this review after using almost a m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Touch is good, mouse is good, comes with a st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Very bed quality ðŸ˜´</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Its not working properly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Battery Backup Very Poor.\\nScreen text get aut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Printer is not working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Good quality and easy to use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Inexpensive. But catriges prices are rip off. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Ratings                                        Full_review\n",
       "0         4.0  I'm writing this review after using almost a m...\n",
       "1         5.0   Touch is good, mouse is good, comes with a st...\n",
       "2         1.0                                 Very bed quality ðŸ˜´\n",
       "3         1.0                           Its not working properly\n",
       "4         1.0  Battery Backup Very Poor.\\nScreen text get aut...\n",
       "...       ...                                                ...\n",
       "14995     5.0                                               Nice\n",
       "14996     5.0                                               Good\n",
       "14997     5.0                             Printer is not working\n",
       "14998     4.0                       Good quality and easy to use\n",
       "14999     3.0  Inexpensive. But catriges prices are rip off. ...\n",
       "\n",
       "[15000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving scraped data into dataframe.\n",
    "search = pd.DataFrame({}) \n",
    "search['Ratings'] = ratings[:15000]\n",
    "search['Full_review'] = reviews[:15000]\n",
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f13b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving scraped data in csv format\n",
    "search.to_csv('Ratings_Prediction_Amazon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25baa9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
